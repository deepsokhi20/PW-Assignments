{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e127a694-2002-41e3-ae95-b86f20a44c5e",
   "metadata": {},
   "source": [
    "#Q1 \n",
    "multiprocessing is a built in package which enables sysytem to run multiple processes simultaneouly. multiprocess means assigning task to different processors.if we give multiple tasks to a single processor it will be difficult for it to carry out all the tasks. So, here comes the multiprocessors in which we can assign different tasks to different processors which will help the computer to run all the tasks more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b839d0c6-bb78-48e5-ad6c-1b08bfa3fcf3",
   "metadata": {},
   "source": [
    "#Q2\n",
    "In Multiprocessing, CPUs are added for increasing computing speed of the system. Because of Multiprocessing, There are many processes are executed simultaneously.\n",
    "In Multithreading is a system in which multiple threads are created of a process for increasing the computing speed of the system. In multithreading, many threads of a process are executed simultaneously.\n",
    "both Multiprocessing and Multithreading are used to increase the computing power of a system.\n",
    "In Multiprocessing, every process owns a separate address space.\n",
    "While in Multithreading, a common address space is shared by all the threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44ad2f6-fb98-4e63-8158-506fda9965be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3\n",
    "import multiprocessing\n",
    "def test():\n",
    "    print(\"testing multiprocessing module\")\n",
    "    process = multiprocessing.Process(target = test)\n",
    "    process.start()\n",
    "    process.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c876b2d-51d5-499a-99c8-9a66692cf731",
   "metadata": {},
   "source": [
    "#Q4 Multiprocessing pool allows tasks to be submitted as functions to the process pool to be executed currently. A process pool object which controls a pool of worker processes to which jobs can be submitted.\n",
    "the multiprocessing.Pool provides a pool of generic worker process. it was designed to be easy and straightforward to use. python multiprocessing pool life cycle comtains create, submit, wait, shutdown. The pool distributes the tasks to the available processors using a FIFO scheduling. It works like a map-reduce architecture. It maps the input to the different processors and collects the output from all the processors. After the execution of code, it returns the output in form of a list or array. It waits for all the tasks to finish and then returns the output. The processes in execution are stored in memory and other non-executing processes are stored out of memory.\n",
    "The pool allows you to do multiple jobs per process, which may make it easier to parallelize your program. If you have a million tasks to execute in parallel, you can create a Pool with a number of processes as many as CPU cores and then pass the list of the million tasks to pool.map. The pool will distribute those tasks to the worker processes and collects the return values in the form of a list and pass it to the parent process. Launching separate million processes would be much less practical.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b716c2a-6b33-4013-9da5-7e5195609248",
   "metadata": {},
   "source": [
    "#Q5\n",
    "The process pool can be created by specifying arguments to be multiprocessing.Pool class contructor.\n",
    "the arguemts of the constructor are as follows:-\n",
    "1. processes - maximum no. of worker processes to use in the pool.\n",
    "2. initializer- function executed after each worker process is created .\n",
    "3. initargs- arguments to the worker process initialization funtion.\n",
    "4. maxtasksperchild- limit the maximum number of tasks executed by each worker process.\n",
    "5. context- configure the multiprocessing context such as the process start method.\n",
    "perhaps the most important arguments is \"processes\" that specifies the number of worker child processes in th process pool. by default multiprocessing.Pool class contructor does not take any argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48c32d8-8a9a-4d3c-9927-f8560f67d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "import multiprocessing\n",
    "def worker_funtion(data):\n",
    "    data= data**2\n",
    "if __name__== '__main__':\n",
    "    pool = multiprocessing.Pool()\n",
    "    data = [1,2,3,4,5]\n",
    "    pool.map(worker_funtion, data)\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3155046b-2a1a-4387-85ba-205fc17b9174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#Q6\n",
    "import multiprocessing\n",
    "def print_number(number):\n",
    "    print(number)\n",
    "if __name__ == '__main__':\n",
    "    processes = []\n",
    "for i in range(1,5):\n",
    "    process = multiprocessing.Process(target = print_number, args=(i, ))\n",
    "    processes.append(process)\n",
    "    process.start()\n",
    "    \n",
    "for process in processes:\n",
    "    process.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec143123-780c-46b4-b819-e87fe96131a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
