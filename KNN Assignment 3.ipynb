{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e38319-6a28-494a-907b-d209a4521807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Q1\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (k) as needed\n",
    "\n",
    "# Train the classifier on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3854a9e7-7871-43bf-b03f-1e64137d55bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 30.94554736842105\n"
     ]
    }
   ],
   "source": [
    "#Q2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Fetch the Boston housing dataset from the original source\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "y = raw_df.values[1::2, 2]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the KNN regressor\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors (k) as needed\n",
    "\n",
    "# Train the regressor on the training data\n",
    "knn_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = knn_reg.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error (MSE) of the regressor\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9331b562-0e74-4266-9596-f71c0d06a5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of k: 6\n"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Define a range of values for k\n",
    "k_values = list(range(1, 21))  # Try k from 1 to 20\n",
    "\n",
    "# Initialize an empty list to store the mean accuracy for each value of k\n",
    "mean_accuracy_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation for each value of k\n",
    "for k in k_values:\n",
    "    # Initialize the KNN classifier with the current value of k\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # Perform 5-fold cross-validation and calculate the mean accuracy\n",
    "    accuracy_scores = cross_val_score(knn, X, y, cv=5, scoring='accuracy')\n",
    "    mean_accuracy = accuracy_scores.mean()\n",
    "    \n",
    "    # Append the mean accuracy to the list\n",
    "    mean_accuracy_scores.append(mean_accuracy)\n",
    "\n",
    "# Find the optimal value of k that maximizes the mean accuracy\n",
    "optimal_k = k_values[mean_accuracy_scores.index(max(mean_accuracy_scores))]\n",
    "\n",
    "print(\"Optimal value of k:\", optimal_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd9d837d-8ad3-48ea-a208-d9932750319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1408907171.2751598\n"
     ]
    }
   ],
   "source": [
    "#Q4\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Fetch the Boston housing dataset\n",
    "boston = fetch_openml(name=\"house_prices\", as_frame=True)\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# Identify non-numeric columns\n",
    "non_numeric_columns = X.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Define preprocessing steps for numeric and non-numeric columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "non_numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute with most frequent value for non-numeric columns\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, ~X.columns.isin(non_numeric_columns)),\n",
    "        ('non_num', non_numeric_transformer, non_numeric_columns)\n",
    "    ])\n",
    "\n",
    "# Define the pipeline with preprocessing and KNN regressor\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('knn_reg', KNeighborsRegressor(n_neighbors=5))])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the pipeline (preprocessing and KNN regressor) on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error (MSE) of the regressor\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7582279-4481-4f09-ac2e-28715c31cc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Q5\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Step 2: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 3: Initialize and fit the KNN classifier with weighted voting\n",
    "# We can use the 'weights' parameter set to 'distance' for weighted voting\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5, weights='distance')  # You can adjust the number of neighbors (k) as needed\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions on the testing set\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the classifier's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ce71bde-5a62-4547-bf4e-f2fe875b2de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize_features(X):\n",
    "    \"\"\"\n",
    "    Standardize the features using StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Feature matrix (2D array-like)\n",
    "\n",
    "    Returns:\n",
    "    - X_scaled: Standardized feature matrix\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e54e57b-26ea-478b-818c-aa7a669d8aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance: 5.0\n"
     ]
    }
   ],
   "source": [
    "#Q7\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points.\n",
    "\n",
    "    Parameters:\n",
    "    - point1: Tuple or array-like containing the coordinates of the first point (e.g., (x1, y1))\n",
    "    - point2: Tuple or array-like containing the coordinates of the second point (e.g., (x2, y2))\n",
    "\n",
    "    Returns:\n",
    "    - distance: Euclidean distance between the two points\n",
    "    \"\"\"\n",
    "    point1 = np.array(point1)\n",
    "    point2 = np.array(point2)\n",
    "    distance = np.sqrt(np.sum((point1 - point2) ** 2))\n",
    "    return distance\n",
    "\n",
    "\n",
    "# Example usage\n",
    "point1 = (1, 2)\n",
    "point2 = (4, 6)\n",
    "distance = euclidean_distance(point1, point2)\n",
    "print(\"Euclidean Distance:\", distance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b68a9660-611e-4a4f-9da7-e9da1f9b5731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan Distance: 7\n"
     ]
    }
   ],
   "source": [
    "#Q8\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def manhattan_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Manhattan distance between two points.\n",
    "\n",
    "    Parameters:\n",
    "    - point1: Tuple or array-like containing the coordinates of the first point (e.g., (x1, y1))\n",
    "    - point2: Tuple or array-like containing the coordinates of the second point (e.g., (x2, y2))\n",
    "\n",
    "    Returns:\n",
    "    - distance: Manhattan distance between the two points\n",
    "    \"\"\"\n",
    "    point1 = np.array(point1)\n",
    "    point2 = np.array(point2)\n",
    "    distance = np.sum(np.abs(point1 - point2))\n",
    "    return distance\n",
    "\n",
    "# Example usage\n",
    "point1 = (1, 2)\n",
    "point2 = (4, 6)\n",
    "distance = manhattan_distance(point1, point2)\n",
    "print(\"Manhattan Distance:\", distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd743c-e7ec-4262-b3ef-ad410bd00ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
